{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amina Tabassum \n",
    "# HW - 04 \n",
    "# NUID : 002190127"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Loading dataset and building input pipeline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version is:  2.4.1\n",
      "datset version is :  4.8.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>,\n",
       " <PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>,\n",
       " <PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print('tensorflow version is: ',tf.__version__)\n",
    "print('datset version is : ', tfds.__version__)\n",
    "\n",
    "#load dataset \n",
    "(training_ds,validation_ds,test_ds),info=tfds.load('mnist',split=['train[:90%]','train[90%:]','test'],shuffle_files=True,as_supervised=True,with_info=True )\n",
    "\n",
    "training_ds,validation_ds,test_ds\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image,label):\n",
    "    image=tf.cast(image,tf.float32)\n",
    "    image=image/255.0\n",
    "    return image,label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n",
      "(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n",
      "(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "buffer_size=10000\n",
    "\n",
    "#training data pipeline\n",
    "training_ds=training_ds.map(normalize_img,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "training_ds=training_ds.cache()\n",
    "training_ds=training_ds.shuffle(buffer_size)\n",
    "training_ds=training_ds.batch(batch_size)\n",
    "training_ds=training_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "#validation data pipeline \n",
    "validation_ds=validation_ds.map(normalize_img,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "validation_ds=validation_ds.batch(batch_size)\n",
    "validation_ds=validation_ds.cache()\n",
    "validation_ds=validation_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "#test data pipeline \n",
    "test_ds=test_ds.map(normalize_img,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds=test_ds.batch(batch_size)\n",
    "test_ds=test_ds.cache()\n",
    "test_ds=test_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(training_ds.element_spec)\n",
    "print(validation_ds.element_spec)\n",
    "print(test_ds.element_spec)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 CNN network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),padding='same',strides=1,activation='relu',input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64,(3,3),padding='same',strides=1,activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Compile CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(tf.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-7,name='Adam'),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "844/844 [==============================] - 58s 68ms/step - loss: 0.2913 - accuracy: 0.9116 - val_loss: 0.0556 - val_accuracy: 0.9835\n",
      "Epoch 2/6\n",
      "844/844 [==============================] - 57s 68ms/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.0454 - val_accuracy: 0.9848\n",
      "Epoch 3/6\n",
      "844/844 [==============================] - 59s 70ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.0439 - val_accuracy: 0.9867\n",
      "Epoch 4/6\n",
      "844/844 [==============================] - 58s 69ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0425 - val_accuracy: 0.9875\n",
      "Epoch 5/6\n",
      "844/844 [==============================] - 59s 70ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.0489 - val_accuracy: 0.9887\n",
      "Epoch 6/6\n",
      "844/844 [==============================] - 59s 70ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0477 - val_accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history=model.fit(training_ds,epochs=6,validation_data=validation_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Evaluate test-set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,625,866\n",
      "Trainable params: 1,625,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 11ms/step - loss: 0.0434 - accuracy: 0.9899\n",
      "test dataset accuracy is: 0.9898999929428101\n",
      "loss is 0.04341074079275131\n"
     ]
    }
   ],
   "source": [
    "testing_loss,testing_Acc=model.evaluate(test_ds)\n",
    "print('test dataset accuracy is:',testing_Acc)\n",
    "print('loss is', testing_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version is:  2.4.1\n",
      "datset version is :  4.8.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>,\n",
       " <PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>,\n",
       " <PrefetchDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print('tensorflow version is: ',tf.__version__)\n",
    "print('datset version is : ', tfds.__version__)\n",
    "\n",
    "#load dataset \n",
    "(training_ds,validation_ds,test_ds),info=tfds.load('mnist',split=['train[:90%]','train[90%:]','test'],shuffle_files=True,as_supervised=True,with_info=True )\n",
    "\n",
    "training_ds,validation_ds,test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image,label):\n",
    "    image=tf.cast(image,tf.float32)\n",
    "    image=image/255.0\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n",
      "(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n",
      "(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "buffer_size=10000\n",
    "\n",
    "#training data pipeline\n",
    "training_ds=training_ds.map(normalize_img,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "training_ds=training_ds.cache()\n",
    "training_ds=training_ds.shuffle(buffer_size)\n",
    "training_ds=training_ds.batch(batch_size)\n",
    "training_ds=training_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "#validation data pipeline \n",
    "validation_ds=validation_ds.map(normalize_img,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "validation_ds=validation_ds.batch(batch_size)\n",
    "validation_ds=validation_ds.cache()\n",
    "validation_ds=validation_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "#test data pipeline \n",
    "test_ds=test_ds.map(normalize_img,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds=test_ds.batch(batch_size)\n",
    "test_ds=test_ds.cache()\n",
    "test_ds=test_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(training_ds.element_spec)\n",
    "print(validation_ds.element_spec)\n",
    "print(test_ds.element_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_mlp=Sequential()\n",
    "model_mlp.add(Flatten())\n",
    "model_mlp.add(Dense(300,activation='relu',input_shape=(784,)))\n",
    "model_mlp.add(Dense(100,activation='relu'))\n",
    "model_mlp.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp.compile(tf.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-7,name='Adam'),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "844/844 [==============================] - 2s 2ms/step - loss: 0.4293 - accuracy: 0.8759 - val_loss: 0.1171 - val_accuracy: 0.9672\n",
      "Epoch 2/6\n",
      "844/844 [==============================] - 2s 2ms/step - loss: 0.0995 - accuracy: 0.9709 - val_loss: 0.1003 - val_accuracy: 0.9682\n",
      "Epoch 3/6\n",
      "844/844 [==============================] - 2s 2ms/step - loss: 0.0643 - accuracy: 0.9804 - val_loss: 0.0867 - val_accuracy: 0.9743\n",
      "Epoch 4/6\n",
      "844/844 [==============================] - 2s 2ms/step - loss: 0.0449 - accuracy: 0.9861 - val_loss: 0.0804 - val_accuracy: 0.9758\n",
      "Epoch 5/6\n",
      "844/844 [==============================] - 2s 2ms/step - loss: 0.0361 - accuracy: 0.9883 - val_loss: 0.0790 - val_accuracy: 0.9775\n",
      "Epoch 6/6\n",
      "844/844 [==============================] - 2s 2ms/step - loss: 0.0282 - accuracy: 0.9909 - val_loss: 0.0800 - val_accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_mlp=model_mlp.fit(training_ds,epochs=6,validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.9782\n",
      "test dataset accuracy is: 0.9782000184059143\n",
      "loss is 0.07590688765048981\n"
     ]
    }
   ],
   "source": [
    "testing_loss,testing_Acc=model_mlp.evaluate(test_ds)\n",
    "print('test dataset accuracy is:',testing_Acc)\n",
    "print('loss is', testing_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_mlp_1=Sequential()\n",
    "model_mlp_1.add(Flatten())\n",
    "model_mlp_1.add(Dense(100,activation='relu',input_shape=(784,)))\n",
    "model_mlp_1.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model_mlp_1.compile(tf.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-7,name='Adam'),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.8509 - val_loss: 0.1995 - val_accuracy: 0.9455\n",
      "Epoch 2/6\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.1655 - accuracy: 0.9523 - val_loss: 0.1337 - val_accuracy: 0.9632\n",
      "Epoch 3/6\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.1110 - accuracy: 0.9677 - val_loss: 0.1166 - val_accuracy: 0.9683\n",
      "Epoch 4/6\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.0855 - accuracy: 0.9742 - val_loss: 0.1035 - val_accuracy: 0.9717\n",
      "Epoch 5/6\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.0676 - accuracy: 0.9801 - val_loss: 0.0974 - val_accuracy: 0.9713\n",
      "Epoch 6/6\n",
      "844/844 [==============================] - 1s 1ms/step - loss: 0.0570 - accuracy: 0.9835 - val_loss: 0.0940 - val_accuracy: 0.9742\n"
     ]
    }
   ],
   "source": [
    "history_mlp_1=model_mlp_1.fit(training_ds,epochs=6,validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_mlp_1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 695us/step - loss: 0.0894 - accuracy: 0.9736\n",
      "test dataset accuracy is: 0.9735999703407288\n",
      "loss is 0.0894041359424591\n"
     ]
    }
   ],
   "source": [
    "testing_loss,testing_Acc=model_mlp_1.evaluate(test_ds)\n",
    "print('test dataset accuracy is:',testing_Acc)\n",
    "print('loss is', testing_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
